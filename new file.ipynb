import json
import csv

def extract_swagger_info(swagger_file_path):
    with open(swagger_file_path, 'r') as file:
        swagger_data = json.load(file)
        
    paths_info = []
    
    # Extract information for each path
    for path, path_data in swagger_data['paths'].items():
        for method, method_data in path_data.items():
            path_info = {
                'path': path,
                'method': method.upper(),
                'description': method_data.get('description', ''),
                'parameters': '',
                'responses': ''
            }
            
            # Extract parameters
            parameters = method_data.get('parameters', [])
            param_descriptions = []
            for parameter in parameters:
                param_description = f"{parameter['name']} ({parameter.get('in', '')}): {parameter.get('description', '')}"
                param_descriptions.append(param_description)
            path_info['parameters'] = ', '.join(param_descriptions)
            
            # Extract responses
            responses = method_data.get('responses', {})
            response_descriptions = []
            for response_code, response_data in responses.items():
                response_description = f"{response_code}: {response_data.get('description', '')}"
                response_descriptions.append(response_description)
            path_info['responses'] = ', '.join(response_descriptions)
            
            paths_info.append(path_info)
    
    return paths_info

def write_swagger_info_to_csv(swagger_info, csv_file_path):
    fieldnames = ['path', 'method', 'description', 'parameters', 'responses']
    with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(swagger_info)

# Example usage:
swagger_file_path = '/path/to/your/swagger_file.json'  # Replace with the actual file path
csv_file_path = '/path/to/your/output_file.csv'  # Replace with the desired output CSV file path

swagger_info = extract_swagger_info(swagger_file_path)
write_swagger_info_to_csv(swagger_info, csv_file_path)



import csv
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load pre-trained GPT-2 model and tokenizer
model_name = "gpt2-medium"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

def generate_documentation(input_text):
    input_ids = tokenizer.encode(input_text, return_tensors='pt')

    # Generate documentation using the model
    output_ids = model.generate(input_ids, max_length=500, num_return_sequences=1, temperature=0.7)
    generated_doc = tokenizer.decode(output_ids[0], skip_special_tokens=True)

    return generated_doc

def generate_documentation_from_csv(csv_file_path):
    with open(csv_file_path, 'r', newline='', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for row in reader:
            input_text = f"Path: {row['path']}\nMethod: {row['method']}\nDescription: {row['description']}\nParameters: {row['parameters']}\nResponses: {row['responses']}"
            generated_documentation = generate_documentation(input_text)
            # Print or save the generated documentation as needed
            print("Generated Documentation:")
            print(generated_documentation)

# Example usage:
csv_file_path = '/path/to/your/csv_file.csv'  # Replace with the actual CSV file path
generate_documentation_from_csv(csv_file_path)
